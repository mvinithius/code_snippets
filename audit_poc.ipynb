# ================================================================
#  AI ASSISTED AUDIT - PROVA DE CONCEITO
#  Notebook base com ingestion, chunking, embeddings, retrieval,
#  prompts, valida√ß√£o, e pipeline de an√°lise.
# ================================================================

# ================================================================
# 1. IMPORTS
# ================================================================

import re
import json
from pathlib import Path
from typing import List, Dict, Optional
from datetime import datetime

import numpy as np
from pydantic import BaseModel, ValidationError

# SentenceTransformer para embeddings
try:
    from sentence_transformers import SentenceTransformer
    model = SentenceTransformer("all-MiniLM-L6-v2")
except:
    model = None
    print("‚ö†Ô∏è SentenceTransformer n√£o instalado. Instale com: pip install sentence-transformers")

# FAISS (opcional)
try:
    import faiss
    faiss_available = True
except:
    faiss_available = False
    print("‚ö†Ô∏è FAISS n√£o instalado. Usando fallback baseado em cosine similarity.")


# ================================================================
# 2. MODELOS Pydantic (para resposta estruturada)
# ================================================================

class ItemCheck(BaseModel):
    item_id: str
    status: str                 # passed | alert | failed
    reason: Optional[str]
    evidence: Optional[List[str]]
    cross_checked_with: Optional[List[str]]
    confidence: Optional[float]


class DocAnalysis(BaseModel):
    doc_id: str
    analyzed_at: str
    overall_status: str
    items: List[ItemCheck]
    raw_llm: Optional[str]


# ================================================================
# 3. Leitura e Segmenta√ß√£o (Chunking)
# ================================================================

def load_markdown(path: str) -> str:
    """Carrega texto markdown do arquivo."""
    return Path(path).read_text(encoding="utf-8")


def chunk_by_headings(md_text: str) -> List[Dict]:
    """Divide o documento por headings (#, ##, ###)."""
    sections = re.split(r"(^#+ .+$)", md_text, flags=re.M)
    chunks = []

    for i in range(1, len(sections), 2):
        heading = sections[i].strip()
        content = sections[i + 1].strip()
        chunk_id = f"chunk-{abs(hash(heading + content))}"

        chunks.append({
            "chunk_id": chunk_id,
            "heading": heading,
            "text": content
        })

    return chunks


# ================================================================
# 4. Embeddings + Indexa√ß√£o
# ================================================================

def embed_texts(texts: List[str]) -> np.ndarray:
    """Cria embeddings via SentenceTransformer."""
    if model is None:
        raise RuntimeError("Modelo de embeddings n√£o carregado.")
    return model.encode(texts, convert_to_numpy=True)


def build_index(embeddings: np.ndarray):
    """Cria √≠ndice FAISS (ou fallback se FAISS indispon√≠vel)."""
    if faiss_available:
        dim = embeddings.shape[1]
        index = faiss.IndexFlatL2(dim)
        index.add(embeddings)
        return index
    else:
        return embeddings


def cosine_similarity(a, b):
    """Fallback para busca sem√¢ntica sem FAISS."""
    a = a / np.linalg.norm(a, axis=1, keepdims=True)
    b = b / np.linalg.norm(b)
    return np.dot(a, b)


def retrieve_similar(query: str, chunks: List[Dict], embeddings, top_k=3):
    """Recupera chunks sem√¢nticos com FAISS ou fallback cosine."""
    q_emb = embed_texts([query])[0]

    if faiss_available:
        D, I = embeddings.search(q_emb.reshape(1, -1), top_k)
        return [chunks[i] for i in I[0]]
    else:
        sims = cosine_similarity(embeddings, q_emb)
        top_idx = np.argsort(sims)[-top_k:][::-1]
        return [chunks[i] for i in top_idx]


# ================================================================
# 5. Regras determin√≠sticas (exemplos simples)
# ================================================================

def rule_contains_term(text: str, term: str) -> bool:
    return term.lower() in text.lower()


def rule_regex(text: str, pattern: str) -> bool:
    return re.search(pattern, text, flags=re.IGNORECASE) is not None


def run_deterministic_rule(check_item: dict, md_text: str):
    """Executa regra determin√≠stica simples."""
    rule_type = check_item.get("type")

    if rule_type == "term":
        ok = rule_contains_term(md_text, check_item["value"])
    elif rule_type == "regex":
        ok = rule_regex(md_text, check_item["value"])
    else:
        return None  # Indica que deve ir para LLM

    status = "passed" if ok else "alert"

    return ItemCheck(
        item_id=check_item["id"],
        status=status,
        reason=f"Regra determin√≠stica: {rule_type}",
        evidence=[],
        cross_checked_with=[],
        confidence=1.0
    )


# ================================================================
# 6. Prompt Construction
# ================================================================

def build_prompt(doc_id: str, check_item: dict, retrieved_chunks: List[Dict]):
    """Cria prompt para a LLM com top-k evid√™ncias."""
    evidence_text = "\n\n".join([f"[{c['heading']}]\n{c['text']}" for c in retrieved_chunks])

    prompt = f"""
Voc√™ √© um auditor especializado.

Avalie o seguinte item do checklist:

Item ID: {check_item["id"]}
Descri√ß√£o: {check_item["description"]}

Documento ID: {doc_id}

EVID√äNCIAS RELEVANTES
--------------------
{evidence_text}

RETORNE APENAS UM JSON COM O SEGUINTE SCHEMA:
{{
 "item_id": "...",
 "status": "passed|alert|failed",
 "reason": "...",
 "evidence": ["..."],
 "cross_checked_with": [],
 "confidence": 0.0
}}
"""
    return prompt


# ================================================================
# 7. Fun√ß√£o mock de chamada √† LLM (substitua pela real)
# ================================================================

def call_llm(prompt: str) -> str:
    """
    MOCK:
    Simula uma resposta da LLM em formato JSON v√°lido.
    Substitua pela integra√ß√£o real com OpenAI, Anthropic, LLaMA etc.
    """
    return json.dumps({
        "item_id": "mock",
        "status": "alert",
        "reason": "Mock: revis√£o necess√°ria",
        "evidence": [],
        "cross_checked_with": [],
        "confidence": 0.5
    })


# ================================================================
# 8. Pipeline de an√°lise completo
# ================================================================

def analyze_document(doc_id: str, md_text: str, checklist: List[dict]):
    chunks = chunk_by_headings(md_text)
    embeddings = embed_texts([c["text"] for c in chunks])
    index = build_index(embeddings)

    results = []

    for item in checklist:
        # 1. Tenta regra determin√≠stica
        det = run_deterministic_rule(item, md_text)
        if det:
            results.append(det)
            continue

        # 2. Recupera chunks relevantes
        retrieved = retrieve_similar(item["description"], chunks, index)

        # 3. Envia para LLM
        prompt = build_prompt(doc_id, item, retrieved)
        llm_raw = call_llm(prompt)

        # 4. Valida com Pydantic
        try:
            parsed = ItemCheck(**json.loads(llm_raw))
        except ValidationError as e:
            print("Erro ao validar resposta da LLM:", e)
            continue

        results.append(parsed)

    # Agrega√ß√£o simples
    overall = "passed"
    if any(r.status == "failed" for r in results):
        overall = "failed"
    elif any(r.status == "alert" for r in results):
        overall = "alert"

    analysis = DocAnalysis(
        doc_id=doc_id,
        analyzed_at=datetime.utcnow().isoformat(),
        overall_status=overall,
        items=results,
        raw_llm=None
    )

    return analysis


# ================================================================
# 9. Exemplo de uso
# ================================================================

# Exemplo de checklist
checklist_example = [
    {"id": "1", "description": "O documento possui a se√ß√£o Plano de Riscos", "type": "term", "value": "Plano de Riscos"},
    {"id": "2", "description": "O documento cont√©m o nome do gerente respons√°vel", "type": "regex", "value": r"Gerente|Respons√°vel"},
    {"id": "3", "description": "Verificar consist√™ncia das datas de release", "type": "llm"}
]

# Exemplo de execu√ß√£o
# md_text = load_markdown("meu_documento.md")
# analysis = analyze_document("DOC-123", md_text, checklist_example)
# print(analysis.json(indent=2))

print("Notebook carregado com sucesso! üöÄ")
