# ================================================================
#  AI ASSISTED AUDIT - PROVA DE CONCEITO (SEM EMBEDDINGS)
# ================================================================

import re
import json
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Optional

import numpy as np
from pydantic import BaseModel, ValidationError


# ================================================================
# 1. MODELOS Pydantic
# ================================================================

class ItemCheck(BaseModel):
    item_id: str
    status: str
    reason: Optional[str]
    evidence: Optional[List[str]]
    cross_checked_with: Optional[List[str]]
    confidence: Optional[float]


class DocAnalysis(BaseModel):
    doc_id: str
    analyzed_at: str
    overall_status: str
    items: List[ItemCheck]
    raw_llm: Optional[str]


# ================================================================
# 2. Leitura e Chunking por headings
# ================================================================

def load_markdown(path: str) -> str:
    return Path(path).read_text(encoding="utf-8")


def chunk_by_headings(md_text: str) -> List[Dict]:
    """Divide o documento em se√ß√µes baseadas em headings"""
    sections = re.split(r"(^#+ .+$)", md_text, flags=re.M)
    chunks = []

    for i in range(1, len(sections), 2):
        heading = sections[i].strip()
        content = sections[i + 1].strip()
        chunk_id = f"chunk-{abs(hash(heading + content))}"

        chunks.append({
            "chunk_id": chunk_id,
            "heading": heading,
            "text": content
        })

    return chunks


# ================================================================
# 3. Regras determin√≠sticas simples
# ================================================================

def rule_contains_term(text: str, term: str) -> bool:
    return term.lower() in text.lower()


def rule_regex(text: str, pattern: str) -> bool:
    return re.search(pattern, text, flags=re.IGNORECASE) is not None


def run_deterministic_rule(check_item: dict, full_text: str):
    rule_type = check_item.get("type")

    if rule_type == "term":
        ok = rule_contains_term(full_text, check_item["value"])
    elif rule_type == "regex":
        ok = rule_regex(full_text, check_item["value"])
    else:
        return None  # sinaliza: enviar para LLM

    return ItemCheck(
        item_id=check_item["id"],
        status="passed" if ok else "alert",
        reason=f"Regra determin√≠stica: {rule_type}",
        evidence=[],
        cross_checked_with=[],
        confidence=1.0
    )


# ================================================================
# 4. Heur√≠stica para encontrar chunks relevantes (sem embeddings)
# ================================================================

def find_relevant_chunks(check_item_desc: str, chunks: List[Dict], top_k=3):
    """Busca chunks por similaridade de palavras simples."""
    words = [w.lower() for w in re.findall(r"\w+", check_item_desc) if len(w) > 3]

    scored = []
    for c in chunks:
        text = (c["heading"] + " " + c["text"]).lower()
        score = sum(text.count(w) for w in words)
        scored.append((score, c))

    scored.sort(key=lambda x: x[0], reverse=True)
    return [c for score, c in scored[:top_k] if score > 0]


# ================================================================
# 5. Prompt para LLM
# ================================================================

def build_prompt(doc_id: str, check_item: dict, retrieved_chunks: List[Dict]):
    evidences = "\n\n".join(
        [f"[{c['heading']}]\n{c['text']}" for c in retrieved_chunks]
    )

    prompt = f"""
Voc√™ √© um auditor especializado.

Item ID: {check_item["id"]}
Descri√ß√£o: {check_item["description"]}

Documento ID: {doc_id}

EVID√äNCIAS ENCONTRADAS:
----------------------
{evidences}

RETORNE APENAS JSON:
{{
 "item_id": "...",
 "status": "passed|alert|failed",
 "reason": "...",
 "evidence": ["..."],
 "cross_checked_with": [],
 "confidence": 0.0
}}
"""
    return prompt


# ================================================================
# 6. Mock da LLM
# ================================================================

def call_llm(prompt: str) -> str:
    """Mock para PoC"""
    return json.dumps({
        "item_id": "mock",
        "status": "alert",
        "reason": "Mock: inconsist√™ncia a verificar",
        "evidence": [],
        "cross_checked_with": [],
        "confidence": 0.5
    })


# ================================================================
# 7. Pipeline completo (sem embeddings)
# ================================================================

def analyze_document(doc_id: str, md_text: str, checklist: List[dict]):
    chunks = chunk_by_headings(md_text)

    results = []

    for item in checklist:
        # 1. regra determin√≠stica
        det = run_deterministic_rule(item, md_text)
        if det:
            results.append(det)
            continue

        # 2. heur√≠stica para achar chunks
        retrieved = find_relevant_chunks(item["description"], chunks)

        # 3. fallback ‚Üí LLM
        prompt = build_prompt(doc_id, item, retrieved)
        llm_raw = call_llm(prompt)

        # 4. valida√ß√£o
        try:
            parsed = ItemCheck(**json.loads(llm_raw))
            results.append(parsed)
        except ValidationError as e:
            print("Erro ao validar resposta:", e)
            continue

    # 5. Agrega√ß√£o final
    if any(r.status == "failed" for r in results):
        overall = "failed"
    elif any(r.status == "alert" for r in results):
        overall = "alert"
    else:
        overall = "passed"

    return DocAnalysis(
        doc_id=doc_id,
        analyzed_at=datetime.utcnow().isoformat(),
        overall_status=overall,
        items=results,
        raw_llm=None
    )


# ================================================================
# 8. Exemplo de uso
# ================================================================

checklist_example = [
    {"id": "1", "description": "Verificar se existe se√ß√£o de riscos", "type": "term", "value": "riscos"},
    {"id": "2", "description": "O documento cont√©m o nome do gerente respons√°vel", "type": "regex", "value": r"Gerente|Respons√°vel"},
    {"id": "3", "description": "Valida√ß√£o das datas de release", "type": "llm"}
]

print("Notebook sem embeddings carregado! üöÄ")
